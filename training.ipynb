{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f98bba5-2267-4f3a-a03a-1cf3c57e2d60",
   "metadata": {},
   "source": [
    "# Rainbow Trading Agent\n",
    "\n",
    "Pytorch implementation based on original Tensorflow implementation from Clement Perroud\n",
    "\n",
    "1. https://github.com/ClementPerroud/RL-Trading-Agent\n",
    "2. https://github.com/ClementPerroud/Rainbow-Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c519cf6-c060-4eb7-813a-bfe8cb62a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "from sklearn.preprocessing import robust_scale\n",
    "\n",
    "from rainbow.agent import Rainbow\n",
    "\n",
    "import sys\n",
    "import gym_trading_env\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c5f65-1ce0-4da6-85e5-fec0b9db2d2a",
   "metadata": {},
   "source": [
    "## Create Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a894a9cb-65af-4b82-b81f-59f5eef66a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  diectory: data/processed/training/*.pkl\n",
      "Using dataset directory: /Users/arcmode/code/trading-rl/data/processed/training/*.pkl\n",
      "Using  diectory: data/processed/training/*.pkl\n",
      "Using dataset directory: /Users/arcmode/code/trading-rl/data/processed/training/*.pkl\n",
      "Using  diectory: data/processed/training/*.pkl\n",
      "Using dataset directory: /Users/arcmode/code/trading-rl/data/processed/training/*.pkl\n",
      "Using  diectory: data/processed/training/*.pkl\n",
      "Using dataset directory: /Users/arcmode/code/trading-rl/data/processed/training/*.pkl\n",
      "Using  diectory: data/processed/training/*.pkl\n",
      "Using dataset directory: /Users/arcmode/code/trading-rl/data/processed/training/*.pkl\n",
      "Using  diectory: data/processed/validation/*.pkl\n",
      "Using dataset directory: /Users/arcmode/code/trading-rl/data/processed/validation/*.pkl\n",
      "Using  diectory: data/processed/validation/*.pkl\n",
      "Using dataset directory: /Users/arcmode/code/trading-rl/data/processed/validation/*.pkl\n",
      "Using  diectory: data/processed/validation/*.pkl\n",
      "Using dataset directory: /Users/arcmode/code/trading-rl/data/processed/validation/*.pkl\n",
      "Using  diectory: data/processed/validation/*.pkl\n",
      "Using dataset directory: /Users/arcmode/code/trading-rl/data/processed/validation/*.pkl\n",
      "Using  diectory: data/processed/validation/*.pkl\n",
      "Using dataset directory: /Users/arcmode/code/trading-rl/data/processed/validation/*.pkl\n"
     ]
    }
   ],
   "source": [
    "def add_features(df):\n",
    "    df[\"feature_close\"] = robust_scale(df[\"close\"].pct_change())\n",
    "    df[\"feature_open\"] = robust_scale(df[\"open\"]/df[\"close\"])\n",
    "    df[\"feature_high\"] = robust_scale(df[\"high\"]/df[\"close\"])\n",
    "    df[\"feature_low\"] = robust_scale(df[\"low\"]/df[\"close\"])\n",
    "    df[\"feature_volume\"] = robust_scale(df[\"volume\"] / df[\"volume\"].rolling(7*24).max())\n",
    "    df.dropna(inplace= True) # Clean your data!\n",
    "    return df\n",
    "\n",
    "\n",
    "def reward_function(history):\n",
    "    return 800*np.log(history[\"portfolio_valuation\", -1] / history[\"portfolio_valuation\", -2]) #log (p_t / p_t-1 )\n",
    "\n",
    "def max_drawdown(history):\n",
    "    networth_array = history['portfolio_valuation']\n",
    "    _max_networth = networth_array[0]\n",
    "    _max_drawdown = 0\n",
    "    for networth in networth_array:\n",
    "        if networth > _max_networth:\n",
    "            _max_networth = networth\n",
    "        drawdown = ( networth - _max_networth ) / _max_networth\n",
    "        if drawdown < _max_drawdown:\n",
    "            _max_drawdown = drawdown\n",
    "    return f\"{_max_drawdown*100:5.2f}%\"\n",
    "\n",
    "def make_env(dir):\n",
    "    print(f\"Using  diectory: {dir}\")\n",
    "    dataset_dir = os.path.join(os.getcwd(), dir)\n",
    "    print(f\"Using dataset directory: {dataset_dir}\")\n",
    "    env = gym.make(\n",
    "        \"MultiDatasetTradingEnv\",\n",
    "        dataset_dir= dir,\n",
    "        preprocess= add_features,\n",
    "        windows= 15,\n",
    "        positions = [ -1, -0.5, 0, 1, 2], # From -1 (=SHORT), to +1 (=LONG)\n",
    "        initial_position = 0,\n",
    "        trading_fees = 0.01/100, # 0.01% per stock buy / sell (Binance fees)\n",
    "        borrow_interest_rate= 0.0003/100, # 0.0003% per timestep (= 1h here)\n",
    "        reward_function = reward_function,\n",
    "        portfolio_initial_value = 1000, # here, in USDT\n",
    "        \n",
    "        verbose= 1,\n",
    "    )\n",
    "    env.unwrapped.add_metric('Position Changes', lambda history : f\"{ 100*np.sum(np.diff(history['position']) != 0)/len(history['position']):5.2f}%\" )\n",
    "    env.unwrapped.add_metric('Max Drawdown', max_drawdown)\n",
    "    return env\n",
    "\n",
    "\n",
    "training_envs = gym.vector.SyncVectorEnv([lambda: make_env(\"data/processed/training/*.pkl\") for _ in range(5)])\n",
    "validation_envs = gym.vector.SyncVectorEnv([lambda: make_env(\"data/processed/validation/*.pkl\") for _ in range(5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d7e5c7-b44e-4f96-b1fd-2eeb96daba8b",
   "metadata": {},
   "source": [
    "## Initialize Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0117cfce-f870-4480-818b-6091b666ff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Rainbow(\n",
    "    simultaneous_training_env = 5,\n",
    "    \n",
    "    #Distributional\n",
    "    distributional= True,\n",
    "    v_min= -200,\n",
    "    v_max = 250,\n",
    "    nb_atoms= 51, \n",
    "    # Prioritized Replay\n",
    "    prioritized_replay = False,\n",
    "    prioritized_replay_alpha= 0.5,\n",
    "    prioritized_replay_beta_function = lambda episode, step : min(1, 0.5 + 0.5*step/150_000),\n",
    "    \n",
    "    # General\n",
    "    multi_steps = 3,\n",
    "    nb_states = 7,\n",
    "    nb_actions = 4,\n",
    "    gamma = 0.99,\n",
    "    replay_capacity = 1E8,\n",
    "    tau = 2000,\n",
    "    \n",
    "    # Model\n",
    "    window= 15,\n",
    "    units = [16,16, 16],\n",
    "    dropout= 0.2,\n",
    "    adversarial= True,\n",
    "    noisy= True,\n",
    "    learning_rate = 3*2.5E-5,\n",
    "\n",
    "    batch_size= 128,\n",
    "    train_every = 10,\n",
    "    epsilon_function = lambda episode, step : max(0.001, (1 - 5E-5)** step),\n",
    "    name = \"Rainbow\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9c2552-cf5c-4386-a29c-deec9c46dffc",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d4272dc-7b8f-4512-9db7-19433ad2bee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(steps = 100_000):\n",
    "    print(\"___________________________________________ TRAINING ___________________________________________\")\n",
    "    if 'obs' not in globals():\n",
    "        global obs\n",
    "        obs, info = training_envs.reset()\n",
    "    for _ in range(steps):\n",
    "        actions = agent.e_greedy_pick_actions(obs)\n",
    "        next_obs, rewards, dones, truncateds, infos = training_envs.step(actions)\n",
    "\n",
    "        agent.store_replays(obs, actions, rewards, next_obs, dones, truncateds)\n",
    "        agent.train()\n",
    "\n",
    "        obs = next_obs\n",
    "\n",
    "def evaluation():\n",
    "    print(\"___________________________________________ VALIDATION ___________________________________________\")\n",
    "    val_obs, info = validation_envs.reset()\n",
    "    check = np.array([False for _ in range(val_obs.shape[0])])\n",
    "    while not np.all(check):\n",
    "        actions = agent.e_greedy_pick_actions(val_obs)\n",
    "        next_obs, rewards, dones, truncateds, infos = validation_envs.step(actions)\n",
    "        val_obs = next_obs\n",
    "        check += dones + truncateds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd7571b-aad6-46d2-a614-bc9559446648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________ TRAINING ___________________________________________\n",
      "___________________________________________ VALIDATION ___________________________________________\n",
      "Market Return : -10.20%   |   Portfolio Return : -68.07%   |   Position Changes : 69.18%   |   Max Drawdown : -71.63%   |   \n",
      "Market Return : -7.66%   |   Portfolio Return : -72.24%   |   Position Changes : 69.24%   |   Max Drawdown : -72.66%   |   \n",
      "Market Return : 43.61%   |   Portfolio Return : -44.70%   |   Position Changes : 70.44%   |   Max Drawdown : -47.02%   |   \n",
      "Market Return : -7.69%   |   Portfolio Return : -62.83%   |   Position Changes : 69.77%   |   Max Drawdown : -65.83%   |   \n",
      "Market Return : 43.46%   |   Portfolio Return : -63.74%   |   Position Changes : 68.97%   |   Max Drawdown : -66.58%   |   \n",
      "___________________________________________ TRAINING ___________________________________________\n",
      "___________________________________________ VALIDATION ___________________________________________\n",
      "Market Return : -10.04%   |   Portfolio Return : -18.13%   |   Position Changes : 68.09%   |   Max Drawdown : -26.89%   |   \n",
      "Market Return : -10.20%   |   Portfolio Return : -38.20%   |   Position Changes : 68.43%   |   Max Drawdown : -39.13%   |   \n",
      "Market Return : -10.20%   |   Portfolio Return : -61.20%   |   Position Changes : 67.19%   |   Max Drawdown : -62.71%   |   \n",
      "Market Return : 43.53%   |   Portfolio Return : -49.97%   |   Position Changes : 67.66%   |   Max Drawdown : -54.25%   |   \n",
      "Market Return : 43.46%   |   Portfolio Return : -55.00%   |   Position Changes : 67.20%   |   Max Drawdown : -57.20%   |   \n",
      "___________________________________________ TRAINING ___________________________________________\n",
      "Market Return : 2694.72%   |   Portfolio Return : -99.75%   |   Position Changes : 65.67%   |   Max Drawdown : -99.78%   |   \n",
      "Market Return : 2694.72%   |   Portfolio Return : -99.90%   |   Position Changes : 65.64%   |   Max Drawdown : -99.90%   |   \n",
      "↳ Env 0 : 000 :    88973   |   00:09:07   |   Epsilon : 0.00%   |   Mean Loss (last 10k) : 1.1357E+00   |   Tot. Rewards : -4793.93   |   Rewards (/1000 steps) :   -53.88   |   Length :  88973\n",
      "↳ Env 1 : 000 :    88973   |   00:09:07   |   Epsilon : 0.00%   |   Mean Loss (last 10k) : 1.1357E+00   |   Tot. Rewards : -5520.95   |   Rewards (/1000 steps) :   -62.05   |   Length :  88973\n",
      "Market Return : 2687.72%   |   Portfolio Return : -99.66%   |   Position Changes : 65.77%   |   Max Drawdown : -99.68%   |   \n",
      "↳ Env 4 : 000 :    88984   |   00:09:07   |   Epsilon : 0.00%   |   Mean Loss (last 10k) : 1.1357E+00   |   Tot. Rewards : -4557.37   |   Rewards (/1000 steps) :   -51.22   |   Length :  88984\n",
      "___________________________________________ VALIDATION ___________________________________________\n",
      "Market Return : -10.13%   |   Portfolio Return :  1.03%   |   Position Changes : 62.01%   |   Max Drawdown : -35.94%   |   \n",
      "Market Return : 39.79%   |   Portfolio Return : -48.64%   |   Position Changes : 63.69%   |   Max Drawdown : -51.99%   |   \n",
      "Market Return : 39.80%   |   Portfolio Return : -49.76%   |   Position Changes : 63.85%   |   Max Drawdown : -52.28%   |   \n",
      "Market Return : 43.61%   |   Portfolio Return : -48.13%   |   Position Changes : 62.14%   |   Max Drawdown : -51.68%   |   \n",
      "Market Return : 43.48%   |   Portfolio Return : -49.32%   |   Position Changes : 63.36%   |   Max Drawdown : -49.86%   |   \n",
      "___________________________________________ TRAINING ___________________________________________\n",
      "Market Return : 1772.87%   |   Portfolio Return : -99.90%   |   Position Changes : 65.66%   |   Max Drawdown : -99.91%   |   \n",
      "Market Return : 1773.47%   |   Portfolio Return : -99.80%   |   Position Changes : 65.50%   |   Max Drawdown : -99.85%   |   \n",
      "↳ Env 2 : 000 :    94242   |   00:10:10   |   Epsilon : 0.00%   |   Mean Loss (last 10k) : 1.1276E+00   |   Tot. Rewards : -5536.77   |   Rewards (/1000 steps) :   -58.75   |   Length :  94242\n",
      "↳ Env 3 : 000 :    94242   |   00:10:10   |   Epsilon : 0.00%   |   Mean Loss (last 10k) : 1.1276E+00   |   Tot. Rewards : -4987.06   |   Rewards (/1000 steps) :   -52.92   |   Length :  94242\n",
      "___________________________________________ VALIDATION ___________________________________________\n",
      "Market Return : -10.20%   |   Portfolio Return : -63.22%   |   Position Changes : 62.25%   |   Max Drawdown : -65.75%   |   \n",
      "Market Return : -7.61%   |   Portfolio Return :  3.41%   |   Position Changes : 64.21%   |   Max Drawdown : -28.51%   |   \n",
      "Market Return : 43.48%   |   Portfolio Return : -38.77%   |   Position Changes : 63.05%   |   Max Drawdown : -43.13%   |   \n",
      "Market Return : -7.79%   |   Portfolio Return : -37.80%   |   Position Changes : 63.26%   |   Max Drawdown : -49.82%   |   \n",
      "Market Return : -7.69%   |   Portfolio Return : -16.15%   |   Position Changes : 64.04%   |   Max Drawdown : -36.87%   |   \n",
      "___________________________________________ TRAINING ___________________________________________\n",
      "___________________________________________ VALIDATION ___________________________________________\n",
      "Market Return : -10.04%   |   Portfolio Return : -16.50%   |   Position Changes : 48.07%   |   Max Drawdown : -49.35%   |   \n",
      "Market Return : 39.79%   |   Portfolio Return : -30.29%   |   Position Changes : 48.95%   |   Max Drawdown : -40.97%   |   \n",
      "Market Return : 39.80%   |   Portfolio Return : -33.90%   |   Position Changes : 49.21%   |   Max Drawdown : -36.88%   |   \n",
      "Market Return : 43.46%   |   Portfolio Return : -39.16%   |   Position Changes : 49.08%   |   Max Drawdown : -41.05%   |   \n",
      "Market Return : 43.46%   |   Portfolio Return : -26.22%   |   Position Changes : 48.95%   |   Max Drawdown : -36.70%   |   \n",
      "___________________________________________ TRAINING ___________________________________________\n",
      "Market Return : 1572.53%   |   Portfolio Return : -97.56%   |   Position Changes : 53.89%   |   Max Drawdown : -97.82%   |   \n",
      "↳ Env 0 : 001 :   178688   |   00:19:44   |   Epsilon : 0.00%   |   Mean Loss (last 10k) : 9.9240E-01   |   Tot. Rewards : -2971.89   |   Rewards (/1000 steps) :   -33.13   |   Length :  89715\n",
      "___________________________________________ VALIDATION ___________________________________________\n",
      "Market Return : -10.09%   |   Portfolio Return : -13.44%   |   Position Changes : 62.27%   |   Max Drawdown : -32.30%   |   \n",
      "Market Return : 39.14%   |   Portfolio Return : -48.29%   |   Position Changes : 61.63%   |   Max Drawdown : -54.87%   |   \n",
      "Market Return : 39.80%   |   Portfolio Return : -27.71%   |   Position Changes : 61.74%   |   Max Drawdown : -33.82%   |   \n",
      "Market Return : -7.61%   |   Portfolio Return : -38.34%   |   Position Changes : 62.35%   |   Max Drawdown : -50.81%   |   \n",
      "Market Return : -7.69%   |   Portfolio Return : -25.48%   |   Position Changes : 62.52%   |   Max Drawdown : -37.70%   |   \n",
      "___________________________________________ TRAINING ___________________________________________\n",
      "Market Return : 1766.58%   |   Portfolio Return : -99.13%   |   Position Changes : 53.59%   |   Max Drawdown : -99.29%   |   \n",
      "↳ Env 1 : 001 :   183218   |   00:20:47   |   Epsilon : 0.00%   |   Mean Loss (last 10k) : 9.9046E-01   |   Tot. Rewards : -3798.18   |   Rewards (/1000 steps) :   -40.30   |   Length :  94245\n",
      "Market Return : 2320.12%   |   Portfolio Return : -97.72%   |   Position Changes : 53.71%   |   Max Drawdown : -98.31%   |   \n",
      "↳ Env 4 : 001 :   183228   |   00:20:47   |   Epsilon : 0.00%   |   Mean Loss (last 10k) : 9.9047E-01   |   Tot. Rewards : -3024.63   |   Rewards (/1000 steps) :   -32.09   |   Length :  94244\n",
      "Market Return : 1575.80%   |   Portfolio Return : -98.30%   |   Position Changes : 52.94%   |   Max Drawdown : -98.69%   |   \n",
      "↳ Env 3 : 001 :   183984   |   00:20:52   |   Epsilon : 0.00%   |   Mean Loss (last 10k) : 9.9005E-01   |   Tot. Rewards : -3261.63   |   Rewards (/1000 steps) :   -36.34   |   Length :  89742\n",
      "Market Return : 2305.81%   |   Portfolio Return : -98.75%   |   Position Changes : 53.65%   |   Max Drawdown : -99.12%   |   \n",
      "↳ Env 2 : 001 :   188486   |   00:21:26   |   Epsilon : 0.00%   |   Mean Loss (last 10k) : 9.8902E-01   |   Tot. Rewards : -3507.65   |   Rewards (/1000 steps) :   -37.22   |   Length :  94244\n",
      "___________________________________________ VALIDATION ___________________________________________\n",
      "Market Return : -10.09%   |   Portfolio Return : -29.15%   |   Position Changes : 30.05%   |   Max Drawdown : -49.05%   |   \n",
      "Market Return : 40.81%   |   Portfolio Return :  6.81%   |   Position Changes : 30.32%   |   Max Drawdown : -33.17%   |   \n",
      "Market Return : 39.14%   |   Portfolio Return : -25.39%   |   Position Changes : 28.52%   |   Max Drawdown : -50.66%   |   \n",
      "Market Return : 39.79%   |   Portfolio Return :  3.16%   |   Position Changes : 29.09%   |   Max Drawdown : -37.95%   |   \n",
      "Market Return : -7.79%   |   Portfolio Return : 21.00%   |   Position Changes : 31.52%   |   Max Drawdown : -37.56%   |   \n",
      "___________________________________________ TRAINING ___________________________________________\n",
      "___________________________________________ VALIDATION ___________________________________________\n",
      "Market Return : -10.06%   |   Portfolio Return : -18.32%   |   Position Changes :  5.78%   |   Max Drawdown : -47.28%   |   \n",
      "Market Return : -10.01%   |   Portfolio Return : -17.81%   |   Position Changes :  5.56%   |   Max Drawdown : -47.87%   |   \n",
      "Market Return : 40.81%   |   Portfolio Return : 35.29%   |   Position Changes :  4.29%   |   Max Drawdown : -28.42%   |   \n",
      "Market Return : 43.43%   |   Portfolio Return : 31.47%   |   Position Changes :  6.04%   |   Max Drawdown : -30.96%   |   \n",
      "Market Return : -7.66%   |   Portfolio Return : -17.49%   |   Position Changes :  6.05%   |   Max Drawdown : -45.32%   |   \n",
      "___________________________________________ TRAINING ___________________________________________\n",
      "___________________________________________ VALIDATION ___________________________________________\n",
      "Market Return : 40.81%   |   Portfolio Return :  4.30%   |   Position Changes : 49.29%   |   Max Drawdown : -22.71%   |   \n",
      "Market Return : 43.61%   |   Portfolio Return : -5.21%   |   Position Changes : 48.67%   |   Max Drawdown : -20.95%   |   \n",
      "Market Return : 43.46%   |   Portfolio Return : -17.24%   |   Position Changes : 48.07%   |   Max Drawdown : -28.93%   |   \n",
      "Market Return : -7.66%   |   Portfolio Return : 14.74%   |   Position Changes : 50.32%   |   Max Drawdown : -26.12%   |   \n",
      "Market Return : 43.46%   |   Portfolio Return : -17.87%   |   Position Changes : 47.87%   |   Max Drawdown : -29.95%   |   \n",
      "___________________________________________ TRAINING ___________________________________________\n",
      "Market Return : 2669.52%   |   Portfolio Return : -55.48%   |   Position Changes : 39.59%   |   Max Drawdown : -83.18%   |   \n",
      "↳ Env 4 : 002 :   272225   |   00:32:18   |   Epsilon : 0.00%   |   Mean Loss (last 10k) : 9.9006E-01   |   Tot. Rewards :  -647.41   |   Rewards (/1000 steps) :    -7.27   |   Length :  88997\n",
      "Market Return : 1773.47%   |   Portfolio Return : -91.55%   |   Position Changes : 41.86%   |   Max Drawdown : -92.99%   |   \n",
      "↳ Env 0 : 002 :   272932   |   00:32:23   |   Epsilon : 0.00%   |   Mean Loss (last 10k) : 9.9021E-01   |   Tot. Rewards : -1977.25   |   Rewards (/1000 steps) :   -20.98   |   Length :  94244\n",
      "Market Return : 1773.47%   |   Portfolio Return : -95.99%   |   Position Changes : 41.09%   |   Max Drawdown : -96.49%   |   \n",
      "↳ Env 1 : 002 :   277462   |   00:32:54   |   Epsilon : 0.00%   |   Mean Loss (last 10k) : 9.9038E-01   |   Tot. Rewards : -2572.17   |   Rewards (/1000 steps) :   -27.29   |   Length :  94244\n",
      "Market Return : 2320.12%   |   Portfolio Return : -96.26%   |   Position Changes : 40.68%   |   Max Drawdown : -96.90%   |   \n",
      "↳ Env 3 : 002 :   278228   |   00:32:59   |   Epsilon : 0.00%   |   Mean Loss (last 10k) : 9.9045E-01   |   Tot. Rewards : -2628.66   |   Rewards (/1000 steps) :   -27.89   |   Length :  94244\n",
      "Market Return : 2308.10%   |   Portfolio Return : -96.12%   |   Position Changes : 39.32%   |   Max Drawdown : -97.08%   |   \n",
      "↳ Env 2 : 002 :   282731   |   00:33:30   |   Epsilon : 0.00%   |   Mean Loss (last 10k) : 9.9133E-01   |   Tot. Rewards : -2600.12   |   Rewards (/1000 steps) :   -27.59   |   Length :  94245\n",
      "___________________________________________ VALIDATION ___________________________________________\n",
      "Market Return : -10.06%   |   Portfolio Return : -31.38%   |   Position Changes : 28.16%   |   Max Drawdown : -51.50%   |   \n",
      "Market Return : 39.14%   |   Portfolio Return : -15.80%   |   Position Changes : 26.99%   |   Max Drawdown : -38.13%   |   \n",
      "Market Return : 43.48%   |   Portfolio Return :  1.75%   |   Position Changes : 26.49%   |   Max Drawdown : -35.58%   |   \n",
      "Market Return : 43.53%   |   Portfolio Return :  0.43%   |   Position Changes : 25.78%   |   Max Drawdown : -32.19%   |   \n",
      "Market Return : -7.78%   |   Portfolio Return : -51.64%   |   Position Changes : 29.74%   |   Max Drawdown : -56.45%   |   \n",
      "___________________________________________ TRAINING ___________________________________________\n",
      "___________________________________________ VALIDATION ___________________________________________\n",
      "Market Return : -7.69%   |   Portfolio Return : -44.55%   |   Position Changes : 40.84%   |   Max Drawdown : -51.70%   |   \n",
      "Market Return : 43.46%   |   Portfolio Return : -13.97%   |   Position Changes : 40.99%   |   Max Drawdown : -38.40%   |   \n",
      "Market Return : -7.71%   |   Portfolio Return : 37.03%   |   Position Changes : 41.72%   |   Max Drawdown : -27.74%   |   \n",
      "Market Return : 43.61%   |   Portfolio Return : -37.52%   |   Position Changes : 41.62%   |   Max Drawdown : -55.30%   |   \n",
      "Market Return : 43.61%   |   Portfolio Return : -33.27%   |   Position Changes : 39.85%   |   Max Drawdown : -41.59%   |   \n",
      "___________________________________________ TRAINING ___________________________________________\n",
      "___________________________________________ VALIDATION ___________________________________________\n",
      "Market Return : -10.04%   |   Portfolio Return : -35.40%   |   Position Changes : 25.01%   |   Max Drawdown : -55.67%   |   \n",
      "Market Return : -10.09%   |   Portfolio Return : -35.58%   |   Position Changes : 24.34%   |   Max Drawdown : -57.42%   |   \n",
      "Market Return : 40.05%   |   Portfolio Return : 25.73%   |   Position Changes : 23.06%   |   Max Drawdown : -31.39%   |   \n",
      "Market Return : 39.32%   |   Portfolio Return : -5.79%   |   Position Changes : 24.84%   |   Max Drawdown : -36.34%   |   \n",
      "Market Return : -7.61%   |   Portfolio Return : -21.83%   |   Position Changes : 24.75%   |   Max Drawdown : -48.90%   |   \n",
      "___________________________________________ TRAINING ___________________________________________\n",
      "Market Return : 2669.52%   |   Portfolio Return : -59.47%   |   Position Changes : 38.64%   |   Max Drawdown : -89.40%   |   \n",
      "↳ Env 0 : 003 :   361929   |   00:45:00   |   Epsilon : 0.00%   |   Mean Loss (last 10k) : 9.9520E-01   |   Tot. Rewards :  -722.59   |   Rewards (/1000 steps) :    -8.12   |   Length :  88997\n",
      "Market Return : 1574.02%   |   Portfolio Return : -89.72%   |   Position Changes : 37.89%   |   Max Drawdown : -92.61%   |   \n",
      "↳ Env 4 : 003 :   361985   |   00:45:01   |   Epsilon : 0.00%   |   Mean Loss (last 10k) : 9.9517E-01   |   Tot. Rewards : -1819.69   |   Rewards (/1000 steps) :   -20.27   |   Length :  89760\n",
      "Market Return : 1572.53%   |   Portfolio Return : -89.67%   |   Position Changes : 38.18%   |   Max Drawdown : -91.73%   |   \n",
      "↳ Env 1 : 003 :   367177   |   00:45:42   |   Epsilon : 0.00%   |   Mean Loss (last 10k) : 9.9453E-01   |   Tot. Rewards : -1816.40   |   Rewards (/1000 steps) :   -20.25   |   Length :  89715\n",
      "Market Return : 2320.59%   |   Portfolio Return : -97.82%   |   Position Changes : 37.71%   |   Max Drawdown : -98.11%   |   \n",
      "↳ Env 3 : 003 :   372472   |   00:46:25   |   Epsilon : 0.00%   |   Mean Loss (last 10k) : 9.9421E-01   |   Tot. Rewards : -3059.88   |   Rewards (/1000 steps) :   -32.47   |   Length :  94244\n",
      "Market Return : 1773.98%   |   Portfolio Return : -91.86%   |   Position Changes : 37.24%   |   Max Drawdown : -92.61%   |   \n",
      "↳ Env 2 : 003 :   376975   |   00:47:00   |   Epsilon : 0.00%   |   Mean Loss (last 10k) : 9.9400E-01   |   Tot. Rewards : -2007.11   |   Rewards (/1000 steps) :   -21.30   |   Length :  94244\n",
      "___________________________________________ VALIDATION ___________________________________________\n",
      "Market Return : -10.06%   |   Portfolio Return :  4.85%   |   Position Changes : 41.60%   |   Max Drawdown : -31.84%   |   \n",
      "Market Return : -10.13%   |   Portfolio Return : -29.84%   |   Position Changes : 41.87%   |   Max Drawdown : -40.46%   |   \n",
      "Market Return : 39.79%   |   Portfolio Return : -10.48%   |   Position Changes : 40.21%   |   Max Drawdown : -34.96%   |   \n",
      "Market Return : -7.69%   |   Portfolio Return : -20.07%   |   Position Changes : 40.48%   |   Max Drawdown : -48.58%   |   \n",
      "Market Return : 43.53%   |   Portfolio Return : -3.89%   |   Position Changes : 38.43%   |   Max Drawdown : -34.32%   |   \n",
      "___________________________________________ TRAINING ___________________________________________\n",
      "___________________________________________ VALIDATION ___________________________________________\n"
     ]
    }
   ],
   "source": [
    "NUM_STEPS = 30_000\n",
    "while True:\n",
    "    train(steps = NUM_STEPS)\n",
    "    evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e0f1da-389e-472d-8099-2e5e14440cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill, pickle\n",
    "#agent.model = None\n",
    "#agent.target_model = None\n",
    "#agent.replay_memory = None\n",
    "\n",
    "with open(\"test.pkl\", \"wb\") as file:\n",
    "    dill.dump(agent, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de34beb7-23b3-486e-84a0-f0fb7f3cb71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_indexes, states, actions, rewards, states_prime, dones, importance_weights = agent.replay_memory.sample(\n",
    "    256,\n",
    "    agent.prioritized_replay_beta_function(agent.episode_count, agent.steps)\n",
    ")\n",
    "results = agent.model(states)\n",
    "\n",
    "action_colors=[\"blue\", \"orange\",\"purple\",\"red\"]\n",
    "fig, axes = plt.subplots(nrows = 2, ncols = 2, figsize=(16,9), dpi=300)\n",
    "for action in range(4):\n",
    "    for i in range(256):\n",
    "        axes[action%2, action//2%2].plot(agent.zs, results[i, action, :], color = action_colors[action], alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be47996-d8e8-46d4-8b7c-b6e97196cabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_indexes, states, actions, rewards, states_prime, dones, importance_weights = agent.replay_memory.sample(\n",
    "    256,\n",
    "    agent.prioritized_replay_beta_function(agent.episode_count, agent.steps)\n",
    ")\n",
    "results = agent.model(states)\n",
    "\n",
    "action_colors=[\"blue\", \"orange\",\"purple\",\"red\"]\n",
    "fig, axes = plt.subplots(nrows = 2, ncols = 2, figsize=(16,9), dpi=300)\n",
    "for action in range(4):\n",
    "    for i in range(1):\n",
    "        axes[action%2, action//2%2].plot(agent.zs, results[i, action, :], color = action_colors[action], alpha = 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
